---
title: "Flood Susceptibility"
---

## The Random Forest Model

The Random Forest (RF) model was adopted to map flood susceptibility across St. Thomas. The training data, consisting of 14 flood-conditioning features, was standardized through a pipeline and input into an RF classifier, with its performance first assessed using a held-out test set. To improve stability and reduce overfitting, model performance was further evaluated through 5-fold stratified cross-validation using ROC–AUC as the scoring metric. A GridSearchCV procedure was implemented to optimize hyperparameters across a search space including the number of trees (50–150), maximum depth (8–None), and minimum samples required for node splits and leaf nodes. The best-performing configuration—identified through cross-validated AUC—included 100 trees, a maximum depth of 10, a minimum of 5 samples to split a node, and 3 samples per leaf, with class weights balanced to address sample imbalance.

Using this optimized model, the RF classifier achieved strong predictive performance (accuracy = 0.85; AUC = 0.94). Class-level precision, recall, and F1 scores remained consistently high for both flooded and non-flooded samples, ranging from 0.82 to 0.88. The ROC curve demonstrates robust discrimination across false-positive rates, confirming the model’s reliability. Feature importance rankings indicate that elevation is the dominant predictor, followed by slope, distance to ghuts, tsunami exposure, and forest cover, while remaining land-cover classes contribute smaller but meaningful signals.

```{python}
#| echo: false
#| include: false 
#| eval: true

!pip install xlrd

import numpy as np
import pandas as pd
import geopandas as gpd
from pathlib import Path
from shapely.geometry import Point
from shapely.ops import unary_union
import rasterio
from rasterio.mask import mask
from rasterio.features import rasterize
from rasterio.transform import from_origin
from scipy.ndimage import distance_transform_edt
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
from pathlib import Path
import geopandas as gpd


import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    roc_curve,
    classification_report,
)

np.random.seed(42)
pd.options.display.max_columns = 200

# Paths
data_dir = Path("data")
processed = data_dir / "processed"

# Vectors 
boundary = gpd.read_file(processed / "st_thomas_boundary.geojson")
flood_zone = gpd.read_file(processed / "flood_zone_st_thomas_3857.gpkg")
tsunami_zone = gpd.read_file(processed / "tsunami_st_thomas_3857.gpkg")
ghuts = gpd.read_file(processed / "ghuts_st_thomas_3857.gpkg")
landcover = gpd.read_file(processed / "landcover_st_thomas_3857.gpkg")
buildings = gpd.read_file(processed / "buildings_st_thomas_3857.gpkg")

# Rasters 
dem_path = processed / "dem_st_thomas_3857.tif"
slope_path = processed / "slope_degrees_3857.tif"
ghut_dist_raster = processed / "ghut_distance_m_3857.tif" 

target_crs = "EPSG:3857"
for gdf in [boundary, flood_zone, tsunami_zone, ghuts, landcover, buildings]:
    if gdf.crs != target_crs:
        gdf.to_crs(target_crs, inplace=True)
        
# Flood inventory: positive/negative samples
high_risk_codes = ["VE", "AE","AO","A"]
flood_field = "FLD_ZONE"  
high_risk = flood_zone[flood_zone[flood_field].isin(high_risk_codes)].copy()
high_risk_geom = high_risk.intersection(boundary.unary_union)

def sample_points_in_polygon(gdf, n_points):
    polys = gdf.geometry.values
    xmin, ymin, xmax, ymax = unary_union(polys).bounds
    pts = []
    while len(pts) < n_points:
        x = np.random.uniform(xmin, xmax)
        y = np.random.uniform(ymin, ymax)
        p = Point(x, y)
        if any(poly.contains(p) for poly in polys):
            pts.append(p)
    return gpd.GeoDataFrame(geometry=pts, crs=gdf.crs)

n_pos = 400
pos_pts = sample_points_in_polygon(high_risk, n_pos)
pos_pts["label"] = 1

# Safe area = boundary - flood zone
safe_area = boundary.overlay(
    flood_zone,
    how="difference",
    keep_geom_type=True 
)

def sample_points_in_safe_area(gdf, n_points, min_elev=5.0):
    union = unary_union(gdf.geometry.values)
    xmin, ymin, xmax, ymax = union.bounds
    pts = []
    with rasterio.open(dem_path) as src:
        for _ in range(n_points * 10):  # safeguard
            if len(pts) >= n_points:
                break
            x = np.random.uniform(xmin, xmax)
            y = np.random.uniform(ymin, ymax)
            p = Point(x, y)
            if union.contains(p):
                z = list(src.sample([(x, y)]))[0][0]
                if z > min_elev:
                    pts.append(p)
    return gpd.GeoDataFrame(geometry=pts, crs=gdf.crs)

n_neg = n_pos
neg_pts = sample_points_in_safe_area(safe_area, n_neg, min_elev=5.0)
neg_pts["label"] = 0

inventory = pd.concat([pos_pts, neg_pts], ignore_index=True)
images_dir = Path("images")
images_dir.mkdir(exist_ok=True)

# reuse existing boundary/inventory; load boundary if missing
try:
    boundary  # noqa: F821
except NameError:
    boundary = gpd.read_file("data/processed/st_thomas_boundary.geojson")

# inventory must already exist in memory (with 'label' column)
# if not, rerun the sampling step that builds pos_pts/neg_pts and concatenates them
if "inventory" not in globals():
    raise RuntimeError("inventory not found; run the sampling step first")

cmap = plt.cm.viridis
colors = cmap(np.linspace(0, 1, 3))
neg_color, pos_color = colors[0], colors[2]

pos_gdf = inventory[inventory["label"] == 1]
neg_gdf = inventory[inventory["label"] == 0]

# Feature extraction helpers
def sample_raster_values(points_gdf, raster_path, col_name):
    with rasterio.open(raster_path) as src:
        coords = [(geom.x, geom.y) for geom in points_gdf.geometry]
        values = [val[0] for val in src.sample(coords)]
    points_gdf[col_name] = values
    return points_gdf

# DEM & slope
inventory = sample_raster_values(inventory, dem_path, "elev")
inventory = sample_raster_values(inventory, slope_path, "slope")

# Tsunami zone flag
inventory["in_tsunami"] = inventory.geometry.apply(
    lambda p: tsunami_zone.contains(p).any()
).astype(int)

# Ghut distance
use_raster_dist = True
if use_raster_dist:
    inventory = sample_raster_values(inventory, ghut_dist_raster, "dist_ghut")
else:
    inventory["dist_ghut"] = inventory.geometry.apply(lambda p: ghuts.distance(p).min())

# Land cover
lc_field = "class" 
landcover = landcover.rename(columns={lc_field: "land_class"})
inventory = gpd.sjoin(inventory, landcover[["land_class", "geometry"]], how="left", predicate="within")
inventory = pd.get_dummies(inventory, columns=["land_class"], prefix="lc")
import os
from pathlib import Path

images_dir = Path("images")
images_dir.mkdir(exist_ok=True)

# ML: Random Forest
feature_cols = [c for c in inventory.columns 
                if c not in ["geometry", "label", "index_right",
                             "rain_annual_mean", "rain_max_month","lc_Rangeland"]]
X = inventory[feature_cols].values
y = inventory["label"].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# Convert training set to DataFrame for correlation analysis
train_df = pd.DataFrame(X_train, columns=feature_cols)

rf_pipe = make_pipeline(
    StandardScaler(),
    RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=3,
        random_state=42,
        class_weight="balanced",
    ),
)
rf_pipe.fit(X_train, y_train)
scores = cross_val_score(rf_pipe, X_train, y_train, cv=5, scoring="roc_auc")

#Best model
pipe = make_pipeline(
    StandardScaler(),
    RandomForestClassifier(random_state=42, class_weight="balanced")
)
param_grid = {
    "randomforestclassifier__n_estimators": [50, 75, 100, 150],
    "randomforestclassifier__max_depth": [8, 10, 12, None],
    "randomforestclassifier__min_samples_split": [2, 5, 10],
    "randomforestclassifier__min_samples_leaf": [1, 3, 5],
}
grid = GridSearchCV(pipe, param_grid, cv=5, scoring="roc_auc", verbose=1, n_jobs=-1)
grid.fit(X_train, y_train)
best_model = grid.best_estimator_
```
```{python}
#| fig-cap: "Figure 1: ROC – Flood Susceptibility Model"
#| fig-alt: "Figure 1: ROC – Flood Susceptibility Model"
#| echo: true
#| code-fold: true
#| code-summary: "Code"

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
from pathlib import Path
import geopandas as gpd

y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)[:, 1]

fpr, tpr, thr = roc_curve(y_test, y_proba)

plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_proba):.3f}")
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

```

```{python}
#| fig-cap: "Figure 2: Feature Importance"
#| fig-alt: "Figure 2: Feature Importance"
#| echo: true
#| code-fold: true
#| code-summary: "Code"

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
from pathlib import Path
import geopandas as gpd

rf_model = best_model.named_steps["randomforestclassifier"]
importance = pd.DataFrame({
    "Feature": feature_cols,
    "Importance": rf_model.feature_importances_
}).sort_values("Importance", ascending=False)

# Create chart
importance = pd.DataFrame({
    "Feature": feature_cols,
    "Importance": rf_model.feature_importances_
}).sort_values("Importance", ascending=False)

ax = importance.sort_values("Importance", ascending=True).plot.barh(
    x="Feature",
    y="Importance",
    figsize=(6, 8),
    legend=False  # no legend by default
)

# Increase font sizes
ax.set_xlabel("Importance", fontsize=12)
ax.set_ylabel("Feature", fontsize=12)
ax.tick_params(axis="both", labelsize=11)

plt.show()

```

## The Flood Susceptibility

With the model validated, the trained RF classifier was applied to the full study area to generate a spatially continuous flood susceptibility map. The flood susceptibility in St Thomas shows a 100 m × 100 m flood susceptibility index ranging from 0.0 (purple, very low) to 1.0 (bright yellow, very high). Values above ~0.8 are concentrated along the coastal fringe, harbors, and embayed shorelines, indicating the most exposed zones. Mid-range values (~0.4–0.7) extend inland along primary drainage corridors. Interior uplands and ridges are dominated by low indices (<0.3), reflecting reduced ponding potential at higher elevations.

```{python}
#| echo: false
#| eval: true

# Predict to grid and write GeoTIFF (rain fields removed)
res = 50  # meters
minx, miny, maxx, maxy = boundary.total_bounds
xs = np.arange(minx, maxx, res)
ys = np.arange(miny, maxy, res)

grid_pts = []
for x in xs:
    for y in ys:
        p = Point(x + res/2, y + res/2)
        if boundary.geometry.unary_union.contains(p):
            grid_pts.append(p)

grid = gpd.GeoDataFrame(geometry=grid_pts, crs=boundary.crs)
grid = sample_raster_values(grid, dem_path, "elev")
grid = sample_raster_values(grid, slope_path, "slope")

if use_raster_dist:
    grid = sample_raster_values(grid, ghut_dist_raster, "dist_ghut")
else:
    grid["dist_ghut"] = grid.geometry.apply(lambda p: ghuts.distance(p).min())

grid = gpd.sjoin(grid, landcover[["land_class", "geometry"]], how="left", predicate="within")
grid = pd.get_dummies(grid, columns=["land_class"], prefix="lc")

# Drop rain fields entirely

grid["in_tsunami"] = grid.geometry.apply(
    lambda p: tsunami_zone.contains(p).any()
).astype(int)

# Ensure all feature columns are present
for c in feature_cols:
    if c not in grid.columns and c not in ["geometry"]:
        grid[c] = 0

X_grid = grid[feature_cols].values
grid["suscept_prob"] = best_model.predict_proba(X_grid)[:, 1]

n_cols = len(xs)
n_rows = len(ys)
transform = from_origin(minx, maxy, res, res)
suscept_arr = np.full((n_rows, n_cols), np.nan, dtype="float32")

for idx, geom in enumerate(grid.geometry):
    x, y = geom.x, geom.y
    col = int((x - minx) // res)
    row = int((maxy - y) // res)
    suscept_arr[row, col] = grid.iloc[idx]["suscept_prob"]

out_path = processed / "st_thomas_flood_susceptibility.tif"
with rasterio.open(
    out_path,
    "w",
    driver="GTiff",
    height=n_rows,
    width=n_cols,
    count=1,
    dtype="float32",
    crs=boundary.crs,
    transform=transform,
    nodata=np.nan,
) as dst:
    dst.write(suscept_arr, 1)
    
valid = np.count_nonzero(~np.isnan(suscept_arr))
suscept_masked = np.ma.masked_invalid(suscept_arr)

```
```{python}
#| fig-cap: "Figure 3: Flood Susceptibility in St Thomas"
#| fig-alt: "Figure 3: Flood Susceptibility in St Thomas"
#| echo: true
#| code-fold: true
#| code-summary: "Code"

import matplotlib.pyplot as plt
import numpy as np

# Mask NaNs
suscept_masked = np.ma.masked_invalid(suscept_arr)

fig, ax = plt.subplots(figsize=(10, 4))

# Dark purple background
fig.patch.set_facecolor("#2b005a")
ax.set_facecolor("#2b005a")

img = ax.imshow(
    suscept_masked,
    extent=(minx, maxx, miny, maxy),
    origin="upper",
    cmap="viridis",
    vmin=0,
    vmax=1,
    interpolation="nearest",
)

# Optional boundary overlay
boundary.boundary.plot(ax=ax, color="white", linewidth=1)

# Horizontal colorbar inset (bottom-left)
cax = ax.inset_axes([0.05, 0.08, 0.25, 0.06])  # [x, y, width, height] in axis fraction
cbar = fig.colorbar(img, cax=cax, orientation="horizontal")
cbar.ax.set_title("Susceptibility Index", fontsize=9, pad=4, color="white")
cbar.outline.set_linewidth(0)
cbar.ax.tick_params(size=0)
cbar.ax.xaxis.set_tick_params(pad=4, colors="white")

ax.set_axis_off()
plt.tight_layout()
plt.show()
```